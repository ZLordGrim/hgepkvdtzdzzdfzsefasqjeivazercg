{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c3d9c3-9997-418e-a836-e795c65044b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18676\\2113295521.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTuneReportCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ray'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import configparser\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "import threading\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import subprocess\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Import Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from ray import tune\n",
    "from ray.tune.integration.xgboost import TuneReportCallback\n",
    "\n",
    "# Import Reinforcement Learning Libraries\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "# Import Data Visualization and Dashboard Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "\n",
    "# Import API Libraries\n",
    "import alpaca_trade_api as tradeapi\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from transformers import pipeline\n",
    "from twilio.rest import Client  # For SMS alerts\n",
    "\n",
    "# Suppress transformers library logs\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Suppress Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up Logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"trading_bot.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load Configuration\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv('MarketCheck.env')\n",
    "\n",
    "# Retrieve Environment Variables\n",
    "ALPACA_API_KEY = os.getenv('ALPACA_API_KEY')\n",
    "ALPACA_SECRET_KEY = os.getenv('ALPACA_SECRET_KEY')\n",
    "ALPACA_BASE_URL = config.get('alpaca', 'base_url', fallback=\"https://paper-api.alpaca.markets\")\n",
    "FINNHUB_API_KEY = os.getenv('FINNHUB_API_KEY')\n",
    "ALPHA_VANTAGE_API_KEY = os.getenv('ALPHA_VANTAGE_API_KEY')\n",
    "TWITTER_API_BEARER_TOKEN = os.getenv('TWITTER_API_BEARER_TOKEN')\n",
    "EMAIL_ADDRESS = os.getenv('EMAIL_ADDRESS')\n",
    "EMAIL_PASSWORD = os.getenv('EMAIL_PASSWORD')\n",
    "SMS_API_KEY = os.getenv('SMS_API_KEY')  # Twilio Account SID\n",
    "SMS_AUTH_TOKEN = os.getenv('SMS_AUTH_TOKEN')  # Twilio Auth Token\n",
    "SMS_FROM_NUMBER = os.getenv('SMS_FROM_NUMBER')  # Twilio Phone Number\n",
    "SMS_TO_NUMBER = os.getenv('SMS_TO_NUMBER')  # Your Phone Number\n",
    "SATELLITE_DATA_API_KEY = os.getenv('SATELLITE_DATA_API_KEY')\n",
    "WEB_TRAFFIC_API_KEY = os.getenv('WEB_TRAFFIC_API_KEY')\n",
    "CREDIT_CARD_DATA_API_KEY = os.getenv('CREDIT_CARD_DATA_API_KEY')\n",
    "DATABASE_URL = os.getenv('DATABASE_URL')\n",
    "\n",
    "def validate_environment_variables(keys=None):\n",
    "    if keys is None:\n",
    "        keys = [\n",
    "            \"ALPACA_API_KEY\",\n",
    "            \"ALPACA_SECRET_KEY\",\n",
    "            \"FINNHUB_API_KEY\",\n",
    "            \"ALPHA_VANTAGE_API_KEY\",\n",
    "            \"TWITTER_API_BEARER_TOKEN\",\n",
    "            \"EMAIL_ADDRESS\",\n",
    "            \"EMAIL_PASSWORD\",\n",
    "            \"SMS_API_KEY\",\n",
    "            \"SMS_AUTH_TOKEN\",\n",
    "            \"SMS_FROM_NUMBER\",\n",
    "            \"SMS_TO_NUMBER\",\n",
    "            \"SATELLITE_DATA_API_KEY\",\n",
    "            \"WEB_TRAFFIC_API_KEY\",\n",
    "            \"CREDIT_CARD_DATA_API_KEY\",\n",
    "            \"DATABASE_URL\"\n",
    "        ]\n",
    "    missing = [key for key in keys if not os.getenv(key)]\n",
    "    if missing:\n",
    "        logging.error(f\"Missing environment variables: {missing}\")\n",
    "        sys.exit(1)\n",
    "    logging.info(\"All environment variables are loaded successfully.\")\n",
    "\n",
    "validate_environment_variables()\n",
    "\n",
    "# Set up Alpaca API\n",
    "api = tradeapi.REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, ALPACA_BASE_URL)\n",
    "\n",
    "class TradingEnvironment(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom OpenAI Gym environment for stock trading simulation.\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df):\n",
    "        super(TradingEnvironment, self).__init__()\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        # Exclude non-numeric columns from observation space\n",
    "        self.feature_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        self.action_space = spaces.Discrete(3)  # Actions: Hold, Buy, Sell\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(len(self.feature_columns),), dtype=np.float32\n",
    "        )\n",
    "        self.current_step = 0\n",
    "        self.balance = 100000  # Starting balance\n",
    "        self.shares_held = 0\n",
    "        self.net_worth = self.balance\n",
    "        self.max_net_worth = self.balance\n",
    "        self.initial_net_worth = self.balance\n",
    "        self.trades = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = 100000\n",
    "        self.shares_held = 0\n",
    "        self.net_worth = self.balance\n",
    "        self.max_net_worth = self.balance\n",
    "        self.initial_net_worth = self.balance\n",
    "        self.trades = []\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        obs = self.df.loc[self.current_step, self.feature_columns].values.astype(np.float32)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        current_price = self.df.loc[self.current_step, 'Close']\n",
    "        reward = 0\n",
    "\n",
    "        # Execute action\n",
    "        if action == 0:  # Hold\n",
    "            pass\n",
    "        elif action == 1:  # Buy\n",
    "            if self.balance >= current_price:\n",
    "                self.shares_held += 1\n",
    "                self.balance -= current_price\n",
    "                self.trades.append({'step': self.current_step, 'shares': 1, 'type': 'buy'})\n",
    "        elif action == 2:  # Sell\n",
    "            if self.shares_held > 0:\n",
    "                self.shares_held -= 1\n",
    "                self.balance += current_price\n",
    "                self.trades.append({'step': self.current_step, 'shares': 1, 'type': 'sell'})\n",
    "\n",
    "        # Update net worth\n",
    "        prev_net_worth = self.net_worth\n",
    "        self.net_worth = self.balance + self.shares_held * current_price\n",
    "        self.max_net_worth = max(self.max_net_worth, self.net_worth)\n",
    "\n",
    "        # Calculate reward as the change in net worth\n",
    "        reward = self.net_worth - prev_net_worth\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        info = {}\n",
    "\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        profit = self.net_worth - self.initial_net_worth\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Balance: {self.balance}')\n",
    "        print(f'Shares held: {self.shares_held}')\n",
    "        print(f'Net worth: {self.net_worth}')\n",
    "        print(f'Profit: {profit}')\n",
    "\n",
    "class TradingBot:\n",
    "    def __init__(self):\n",
    "        # Load settings from configuration\n",
    "        self.ticker = config.get('trading', 'ticker', fallback='AAPL')\n",
    "        self.start_date = config.get('trading', 'start_date', fallback='2020-01-01')\n",
    "        self.end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        self.interval = config.getint('trading', 'interval', fallback=3600)\n",
    "        self.initial_cash = config.getfloat('portfolio', 'initial_cash', fallback=100000.0)\n",
    "        self.portfolio = {\n",
    "            \"cash\": self.initial_cash,\n",
    "            \"holdings\": 0,\n",
    "            \"equity\": self.initial_cash\n",
    "        }\n",
    "        self.model = None\n",
    "        self.rl_model = None\n",
    "        self.scaler = None\n",
    "\n",
    "        # Initialize sentiment analysis pipeline with FinBERT\n",
    "        self.sentiment_model = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"ProsusAI/finbert\",\n",
    "            tokenizer=\"ProsusAI/finbert\"\n",
    "        )\n",
    "\n",
    "        # Initialize UI components\n",
    "        self.dashboard_thread = threading.Thread(target=self.run_dashboard)\n",
    "        self.dashboard_thread.daemon = True\n",
    "        self.dashboard_thread.start()\n",
    "\n",
    "        # Initialize database connection\n",
    "        self.engine = create_engine(DATABASE_URL)\n",
    "\n",
    "    def get_market_data(self):\n",
    "        logging.info(f'Fetching market data for {self.ticker}')\n",
    "        try:\n",
    "            # Option to use Alpha Vantage API\n",
    "            data = self.fetch_alpha_vantage_data()\n",
    "            if data.empty:\n",
    "                # Fallback to yfinance if Alpha Vantage fails\n",
    "                data = yf.download(\n",
    "                    self.ticker, start=self.start_date, end=self.end_date, interval='1d', progress=False\n",
    "                )\n",
    "            data.reset_index(inplace=True)\n",
    "            data.rename(columns={'Date': 'timestamp'}, inplace=True)\n",
    "            # Fetch alternative data sources and merge\n",
    "            alternative_data = self.get_alternative_data()\n",
    "            if not alternative_data.empty:\n",
    "                data = pd.merge(data, alternative_data, on='timestamp', how='left')\n",
    "            # Store data to the database\n",
    "            data.to_sql('market_data', con=self.engine, if_exists='replace', index=False)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching market data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def fetch_alpha_vantage_data(self):\n",
    "        logging.info(\"Fetching data from Alpha Vantage API...\")\n",
    "        try:\n",
    "            url = (\n",
    "                f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED'\n",
    "                f'&symbol={self.ticker}&outputsize=full&apikey={ALPHA_VANTAGE_API_KEY}&datatype=csv'\n",
    "            )\n",
    "            data = pd.read_csv(url)\n",
    "            data.rename(columns={'timestamp': 'Date'}, inplace=True)\n",
    "            data['Date'] = pd.to_datetime(data['timestamp'])\n",
    "            data.sort_values('Date', inplace=True)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Alpha Vantage API failed: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def get_alternative_data(self):\n",
    "        logging.info(\"Fetching alternative data sources...\")\n",
    "        try:\n",
    "            # Fetch satellite data\n",
    "            satellite_data = self.fetch_satellite_data()\n",
    "            # Fetch web traffic data\n",
    "            web_traffic_data = self.fetch_web_traffic_data()\n",
    "            # Fetch credit card transaction data\n",
    "            credit_card_data = self.fetch_credit_card_data()\n",
    "            # Merge all alternative data\n",
    "            alternative_data = pd.merge(satellite_data, web_traffic_data, on='timestamp', how='outer')\n",
    "            alternative_data = pd.merge(alternative_data, credit_card_data, on='timestamp', how='outer')\n",
    "            return alternative_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching alternative data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def fetch_satellite_data(self):\n",
    "        logging.info(\"Fetching satellite data...\")\n",
    "        try:\n",
    "            # Placeholder for actual satellite data fetching using NASA Earth API\n",
    "            date_range = pd.date_range(start=self.start_date, end=self.end_date)\n",
    "            satellite_data = pd.DataFrame({\n",
    "                'timestamp': date_range,\n",
    "                'satellite_activity': np.random.rand(len(date_range))\n",
    "            })\n",
    "            return satellite_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching satellite data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def fetch_web_traffic_data(self):\n",
    "        logging.info(\"Fetching web traffic data...\")\n",
    "        try:\n",
    "            # Placeholder for actual web traffic data fetching using OpenPageRank API\n",
    "            date_range = pd.date_range(start=self.start_date, end=self.end_date)\n",
    "            web_traffic_data = pd.DataFrame({\n",
    "                'timestamp': date_range,\n",
    "                'web_traffic': np.random.randint(1000, 10000, size=len(date_range))\n",
    "            })\n",
    "            return web_traffic_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching web traffic data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def fetch_credit_card_data(self):\n",
    "        logging.info(\"Fetching credit card transaction data...\")\n",
    "        try:\n",
    "            # Placeholder for actual credit card data fetching\n",
    "            date_range = pd.date_range(start=self.start_date, end=self.end_date)\n",
    "            credit_card_data = pd.DataFrame({\n",
    "                'timestamp': date_range,\n",
    "                'credit_card_spend': np.random.randint(10000, 100000, size=len(date_range))\n",
    "            })\n",
    "            return credit_card_data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching credit card data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    async def get_news_headlines(self):\n",
    "        logging.info(f\"Fetching company-specific news for {self.ticker}\")\n",
    "        try:\n",
    "            # Asynchronously fetch news from multiple sources\n",
    "            news_data = await asyncio.gather(\n",
    "                self.fetch_finnhub_news(),\n",
    "                self.fetch_twitter_sentiment()\n",
    "            )\n",
    "            # Combine data\n",
    "            news_df = pd.concat(news_data, ignore_index=True)\n",
    "            return news_df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching news headlines: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    async def fetch_finnhub_news(self):\n",
    "        logging.info(f\"Fetching news from Finnhub for {self.ticker}\")\n",
    "        today = datetime.today().strftime('%Y-%m-%d')\n",
    "        one_month_ago = (datetime.today() - timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "        url = (\n",
    "            f\"https://finnhub.io/api/v1/company-news?symbol={self.ticker}\"\n",
    "            f\"&from={one_month_ago}&to={today}&token={FINNHUB_API_KEY}\"\n",
    "        )\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    articles = await response.json()\n",
    "                    headlines = [\n",
    "                        {\n",
    "                            'date': pd.to_datetime(article.get('datetime'), unit='s').date(),\n",
    "                            'headline': article.get('headline'),\n",
    "                            'description': article.get('summary')\n",
    "                        }\n",
    "                        for article in articles\n",
    "                    ]\n",
    "                    return pd.DataFrame(headlines)\n",
    "                else:\n",
    "                    logging.warning(f\"Failed to fetch Finnhub news: {response.status}\")\n",
    "                    return pd.DataFrame(columns=['date', 'headline', 'description'])\n",
    "\n",
    "    async def fetch_twitter_sentiment(self):\n",
    "        logging.info(f\"Fetching Twitter sentiment for {self.ticker}\")\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {TWITTER_API_BEARER_TOKEN}\"\n",
    "        }\n",
    "        query = f\"${self.ticker} -is:retweet lang:en\"\n",
    "        url = f\"https://api.twitter.com/2/tweets/search/recent?query={query}&tweet.fields=created_at\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url, headers=headers) as response:\n",
    "                if response.status == 200:\n",
    "                    tweets = await response.json()\n",
    "                    tweet_data = [\n",
    "                        {\n",
    "                            'date': pd.to_datetime(tweet['created_at']).date(),\n",
    "                            'headline': tweet['text']\n",
    "                        }\n",
    "                        for tweet in tweets.get('data', [])\n",
    "                    ]\n",
    "                    return pd.DataFrame(tweet_data)\n",
    "                else:\n",
    "                    logging.warning(f\"Failed to fetch Twitter data: {response.status}\")\n",
    "                    return pd.DataFrame(columns=['date', 'headline'])\n",
    "\n",
    "    def analyze_sentiment(self, headlines_df):\n",
    "        logging.info('Analyzing sentiment...')\n",
    "        if headlines_df.empty:\n",
    "            logging.warning(\"No headlines available for sentiment analysis.\")\n",
    "            return pd.DataFrame(columns=['date', 'sentiment'])\n",
    "        try:\n",
    "            # Use the FinBERT model for financial sentiment analysis\n",
    "            sentiments = self.sentiment_model(\n",
    "                headlines_df['headline'].tolist(), truncation=True, max_length=512\n",
    "            )\n",
    "            headlines_df['sentiment_score'] = [\n",
    "                1 if s['label'].lower() == 'positive' else (-1 if s['label'].lower() == 'negative' else 0)\n",
    "                for s in sentiments\n",
    "            ]\n",
    "            headlines_df['date'] = pd.to_datetime(headlines_df['date'])\n",
    "            return headlines_df.groupby('date')['sentiment_score'].mean().reset_index().rename(\n",
    "                columns={'sentiment_score': 'sentiment'}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during sentiment analysis: {e}\")\n",
    "            return pd.DataFrame(columns=['date', 'sentiment'])\n",
    "\n",
    "    def preprocess_data(self, market_data, sentiment_data):\n",
    "        logging.info(\"Preprocessing data...\")\n",
    "        try:\n",
    "            # Feature Engineering\n",
    "            data = self.feature_engineering(market_data)\n",
    "            # Merge with sentiment data\n",
    "            data = self.merge_sentiment_data(data, sentiment_data)\n",
    "            # Data Scaling\n",
    "            data = self.scale_features(data)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in preprocessing data: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def feature_engineering(self, data):\n",
    "        # Advanced technical indicators\n",
    "        data['EMA_12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "        data['EMA_26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "        data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
    "        data['RSI'] = self.calculate_rsi(data['Close'])\n",
    "        data['BB_upper'], data['BB_middle'], data['BB_lower'] = self.calculate_bollinger_bands(data['Close'])\n",
    "        # Additional indicators can be added here\n",
    "        return data\n",
    "\n",
    "    def calculate_rsi(self, series, period=14):\n",
    "        delta = series.diff(1)\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = -delta.clip(upper=0)\n",
    "        avg_gain = gain.ewm(alpha=1/period, adjust=False).mean()\n",
    "        avg_loss = loss.ewm(alpha=1/period, adjust=False).mean()\n",
    "        rs = avg_gain / avg_loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi.fillna(0)\n",
    "\n",
    "    def calculate_bollinger_bands(self, series, period=20, num_std=2):\n",
    "        rolling_mean = series.rolling(window=period).mean()\n",
    "        rolling_std = series.rolling(window=period).std()\n",
    "        upper_band = rolling_mean + (rolling_std * num_std)\n",
    "        lower_band = rolling_mean - (rolling_std * num_std)\n",
    "        return upper_band.fillna(0), rolling_mean.fillna(0), lower_band.fillna(0)\n",
    "\n",
    "    def merge_sentiment_data(self, data, sentiment_data):\n",
    "        if not sentiment_data.empty:\n",
    "            sentiment_data['date'] = pd.to_datetime(sentiment_data['date'])\n",
    "            data['date'] = pd.to_datetime(data['timestamp']).dt.date\n",
    "            data = pd.merge(\n",
    "                data, sentiment_data, left_on='date', right_on='date', how='left'\n",
    "            )\n",
    "            data['sentiment'].fillna(0, inplace=True)\n",
    "        else:\n",
    "            data['sentiment'] = 0\n",
    "        return data\n",
    "\n",
    "    def scale_features(self, data):\n",
    "        features = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        features = [f for f in features if f not in ['Close', 'Adj Close']]\n",
    "        self.scaler = StandardScaler()\n",
    "        data[features] = self.scaler.fit_transform(data[features])\n",
    "        return data\n",
    "\n",
    "    def train_model(self, data):\n",
    "        logging.info(\"Training predictive model...\")\n",
    "        try:\n",
    "            # Prepare data for training\n",
    "            X = data.drop(columns=['timestamp', 'date', 'Close', 'Adj Close'], errors='ignore')\n",
    "            y = data['Close']\n",
    "            # Use Ray Tune for hyperparameter tuning\n",
    "            self.model = self.train_with_ray_tune(X, y)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training model: {e}\")\n",
    "\n",
    "    def train_with_ray_tune(self, X, y):\n",
    "        def train_model(config):\n",
    "            train_set = xgb.DMatrix(X, label=y)\n",
    "            result = {}\n",
    "            xgb.train(\n",
    "                config,\n",
    "                train_set,\n",
    "                evals=[(train_set, \"train\")],\n",
    "                verbose_eval=False,\n",
    "                evals_result=result\n",
    "            )\n",
    "            tune.report(loss=result[\"train\"][\"rmse\"][-1])\n",
    "\n",
    "        search_space = {\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"eval_metric\": \"rmse\",\n",
    "            \"max_depth\": tune.randint(3, 10),\n",
    "            \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
    "            \"min_child_weight\": tune.randint(1, 10),\n",
    "            \"subsample\": tune.uniform(0.5, 1.0),\n",
    "            \"colsample_bytree\": tune.uniform(0.5, 1.0),\n",
    "        }\n",
    "\n",
    "        analysis = tune.run(\n",
    "            train_model,\n",
    "            config=search_space,\n",
    "            num_samples=50,\n",
    "            resources_per_trial={\"cpu\": 2},\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        best_config = analysis.get_best_config(metric=\"loss\", mode=\"min\")\n",
    "        logging.info(f\"Best hyperparameters found: {best_config}\")\n",
    "        # Train final model with best hyperparameters\n",
    "        final_model = xgb.XGBRegressor(**best_config)\n",
    "        final_model.fit(X, y)\n",
    "        return final_model\n",
    "\n",
    "    def train_reinforcement_learning_agent(self, data):\n",
    "        logging.info(\"Training reinforcement learning agent...\")\n",
    "        try:\n",
    "            env = TradingEnvironment(data)\n",
    "            env = DummyVecEnv([lambda: env])\n",
    "\n",
    "            model = PPO('MlpPolicy', env, verbose=0)\n",
    "            model.learn(total_timesteps=10000)\n",
    "            self.rl_model = model\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training RL agent: {e}\")\n",
    "\n",
    "    def decide_trading_action(self, latest_row, data):\n",
    "        logging.info(\"Evaluating trading action...\")\n",
    "        try:\n",
    "            # Machine Learning Model Prediction\n",
    "            X_latest = latest_row.drop(labels=['timestamp', 'date', 'Close', 'Adj Close'], errors='ignore').values.reshape(1, -1)\n",
    "            X_scaled = self.scaler.transform(X_latest)\n",
    "            predicted_price = self.model.predict(X_scaled)[0]\n",
    "            current_price = latest_row['Close']\n",
    "            logging.info(f\"Predicted price: {predicted_price}, Current price: {current_price}\")\n",
    "\n",
    "            # Reinforcement Learning Agent Decision\n",
    "            obs = X_scaled.flatten()\n",
    "            action_rl, _ = self.rl_model.predict(obs, deterministic=True)\n",
    "            logging.info(f\"RL Agent Action: {action_rl}\")\n",
    "\n",
    "            # Combine Decisions\n",
    "            expected_return = (predicted_price - current_price) / current_price\n",
    "\n",
    "            # Risk-adjusted position sizing\n",
    "            close_prices = data['Close']\n",
    "            volatility = close_prices[-20:].std()  # Last 20 days\n",
    "            if np.isnan(volatility) or volatility == 0:\n",
    "                volatility = close_prices.std()\n",
    "            position_size = self.calculate_position_size(expected_return, volatility)\n",
    "\n",
    "            # Determine final action\n",
    "            if action_rl == 1 and expected_return > 0.005:\n",
    "                return \"BUY\", position_size\n",
    "            elif action_rl == 2 and expected_return < -0.005:\n",
    "                return \"SELL\", position_size\n",
    "            else:\n",
    "                return \"HOLD\", 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in deciding trading action: {e}\")\n",
    "            return \"HOLD\", 0\n",
    "\n",
    "    def calculate_position_size(self, expected_return, volatility):\n",
    "        risk_per_trade = 0.01  # 1% of equity\n",
    "        account_equity = self.portfolio['equity']\n",
    "        if volatility == 0 or np.isnan(volatility):\n",
    "            volatility = 1  # Prevent division by zero\n",
    "        position_size = (account_equity * risk_per_trade) / volatility\n",
    "        return min(position_size, account_equity * 0.2)  # Max 20% of equity\n",
    "\n",
    "    def execute_trade(self, action, amount, latest_row):\n",
    "        try:\n",
    "            if action == \"BUY\":\n",
    "                buying_power = float(api.get_account().buying_power)\n",
    "                quantity = int(amount // latest_row['Close'])\n",
    "                if quantity > 0 and quantity * latest_row['Close'] <= buying_power:\n",
    "                    api.submit_order(\n",
    "                        symbol=self.ticker, qty=quantity, side=\"buy\",\n",
    "                        type=\"market\", time_in_force=\"gtc\"\n",
    "                    )\n",
    "                    self.portfolio['cash'] -= quantity * latest_row['Close']\n",
    "                    self.portfolio['holdings'] += quantity\n",
    "                    logging.info(f\"Bought {quantity} shares of {self.ticker}\")\n",
    "                    self.send_alert(f\"Bought {quantity} shares of {self.ticker}\")\n",
    "                else:\n",
    "                    logging.info(\"Insufficient funds to buy.\")\n",
    "            elif action == \"SELL\":\n",
    "                try:\n",
    "                    position = api.get_position(self.ticker)\n",
    "                    quantity = int(position.qty)\n",
    "                    if quantity > 0:\n",
    "                        api.submit_order(\n",
    "                            symbol=self.ticker, qty=quantity, side=\"sell\",\n",
    "                            type=\"market\", time_in_force=\"gtc\"\n",
    "                        )\n",
    "                        self.portfolio['cash'] += quantity * latest_row['Close']\n",
    "                        self.portfolio['holdings'] -= quantity\n",
    "                        logging.info(f\"Sold {quantity} shares of {self.ticker}\")\n",
    "                        self.send_alert(f\"Sold {quantity} shares of {self.ticker}\")\n",
    "                    else:\n",
    "                        logging.info(\"No holdings to sell.\")\n",
    "                except Exception:\n",
    "                    logging.info(\"No position to sell.\")\n",
    "            else:\n",
    "                logging.info(\"No action taken.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error executing trade: {e}\")\n",
    "\n",
    "    def update_portfolio(self):\n",
    "        try:\n",
    "            account = api.get_account()\n",
    "            self.portfolio['cash'] = float(account.cash)\n",
    "            self.portfolio['equity'] = float(account.equity)\n",
    "            try:\n",
    "                position = api.get_position(self.ticker)\n",
    "                self.portfolio['holdings'] = int(position.qty)\n",
    "            except Exception:\n",
    "                self.portfolio['holdings'] = 0\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error updating portfolio: {e}\")\n",
    "\n",
    "    def send_alert(self, message):\n",
    "        # Send email alert\n",
    "        try:\n",
    "            msg = MIMEText(message)\n",
    "            msg['Subject'] = 'Trading Bot Alert'\n",
    "            msg['From'] = EMAIL_ADDRESS\n",
    "            msg['To'] = EMAIL_ADDRESS  # Send to self; can be adjusted\n",
    "\n",
    "            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
    "                server.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
    "                server.sendmail(EMAIL_ADDRESS, EMAIL_ADDRESS, msg.as_string())\n",
    "            logging.info(\"Alert email sent.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending alert email: {e}\")\n",
    "\n",
    "        # Send SMS alert using Twilio\n",
    "        try:\n",
    "            client = Client(SMS_API_KEY, SMS_AUTH_TOKEN)\n",
    "            message = client.messages.create(\n",
    "                body=message,\n",
    "                from_=SMS_FROM_NUMBER,\n",
    "                to=SMS_TO_NUMBER\n",
    "            )\n",
    "            logging.info(\"SMS alert sent.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending SMS alert: {e}\")\n",
    "\n",
    "    def run_dashboard(self):\n",
    "        # Streamlit code to create dashboard\n",
    "        st.title('Trading Bot Dashboard')\n",
    "        placeholder = st.empty()\n",
    "        while True:\n",
    "            with placeholder.container():\n",
    "                st.write('Portfolio State')\n",
    "                st.write(self.portfolio)\n",
    "                # Additional components can be added here\n",
    "                time.sleep(5)\n",
    "\n",
    "    async def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                # Fetch data\n",
    "                market_data = self.get_market_data()\n",
    "                if market_data.empty:\n",
    "                    logging.warning(\"Market data is empty. Skipping iteration.\")\n",
    "                    await asyncio.sleep(self.interval)\n",
    "                    continue\n",
    "                headlines = await self.get_news_headlines()\n",
    "                sentiment = self.analyze_sentiment(headlines)\n",
    "                processed_data = self.preprocess_data(market_data, sentiment)\n",
    "                if processed_data.empty:\n",
    "                    logging.warning(\"Processed data is empty. Skipping iteration.\")\n",
    "                    await asyncio.sleep(self.interval)\n",
    "                    continue\n",
    "                self.train_model(processed_data)\n",
    "                self.train_reinforcement_learning_agent(processed_data)\n",
    "                latest_row = processed_data.iloc[-1]\n",
    "\n",
    "                # Update portfolio\n",
    "                self.update_portfolio()\n",
    "\n",
    "                # Make trading decision\n",
    "                action, amount = self.decide_trading_action(latest_row, processed_data)\n",
    "                self.execute_trade(action, amount, latest_row)\n",
    "                logging.info(f\"Updated portfolio state: {self.portfolio}\")\n",
    "\n",
    "                # Sleep until next interval\n",
    "                logging.info(f\"Sleeping for {self.interval} seconds...\")\n",
    "                await asyncio.sleep(self.interval)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"An error occurred in the main loop: {e}\")\n",
    "                await asyncio.sleep(self.interval)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bot = TradingBot()\n",
    "    asyncio.run(bot.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f519f117-a402-47a4-8a8f-99703661df61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0ee54-78f0-41ef-83c5-416af00fa818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
